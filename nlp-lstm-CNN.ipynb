{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, recall_score, accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Conv1D, MaxPooling1D, Dense, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\W', ' ', str(text))\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text\n",
    "\n",
    "# Function to predict spam/ham category\n",
    "def predict_spam_ham(text, model, tokenizer, max_len, label_encoder):\n",
    "    cleaned_text = clean_text(text)\n",
    "    sequence = tokenizer.texts_to_sequences([cleaned_text])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=max_len)\n",
    "    prediction = model.predict(padded_sequence)\n",
    "    return label_encoder.inverse_transform(np.argmax(prediction, axis=1))[0]\n",
    "\n",
    "# Function to plot training metrics\n",
    "def plot_training_metrics(history, img_prefix='training'):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    # Accuracy plot\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, acc, 'bo-', label='Training Accuracy')\n",
    "    plt.plot(epochs, val_acc, 'ro-', label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'{img_prefix}_accuracy.png')  # Save as image\n",
    "    plt.show()\n",
    "\n",
    "    # Loss plot\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'bo-', label='Training Loss')\n",
    "    plt.plot(epochs, val_loss, 'ro-', label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'{img_prefix}_loss.png')  # Save as image\n",
    "    plt.show()\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('enron_05_17_2015_with_labels_v2.csv')\n",
    "\n",
    "# Display initial data information\n",
    "print(df.head())\n",
    "\n",
    "# Combine and clean text data\n",
    "df['Text'] = df['Subject'].fillna('') + ' ' + df['content'].fillna('')\n",
    "df['Text'] = df['Text'].apply(clean_text)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "df['Label'] = label_encoder.fit_transform(df['labeled'])\n",
    "\n",
    "# Tokenization and Padding\n",
    "MAX_WORDS = 10000\n",
    "MAX_LEN = 100\n",
    "tokenizer = Tokenizer(num_words=MAX_WORDS)\n",
    "tokenizer.fit_on_texts(df['Text'])\n",
    "sequences = tokenizer.texts_to_sequences(df['Text'])\n",
    "X = pad_sequences(sequences, maxlen=MAX_LEN)\n",
    "y = df['Label']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Building the model\n",
    "def create_model(dropout_rate=0.0, optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(MAX_WORDS, 128, input_length=MAX_LEN))\n",
    "    model.add(Conv1D(64, 5, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=4))\n",
    "    model.add(LSTM(64))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create model\n",
    "model = KerasClassifier(model=create_model, verbose=0)\n",
    "\n",
    "# Define the grid search parameters with model__ prefix\n",
    "param_grid = {\n",
    "    'model__dropout_rate': [0.1, 0.5, 0.9],\n",
    "    'model__optimizer': ['adam', 'nadam', 'sgd'],\n",
    "    'batch_size': [10, 20, 50],\n",
    "    'epochs': [10, 50, 100]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Summarize results\n",
    "print(f\"Best: {grid_result.best_score_:.2f} using {grid_result.best_params_}\")\n",
    "\n",
    "# Train the best model\n",
    "best_model = grid_result.best_estimator_\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = best_model.model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Plot training metrics\n",
    "plot_training_metrics(best_model.model.history, img_prefix='best_model')\n",
    "\n",
    "# Example prediction\n",
    "example_text = \"Win a brand new car! Click here for details.\"\n",
    "prediction = predict_spam_ham(example_text, best_model.model, tokenizer, MAX_LEN, label_encoder)\n",
    "print(f\"Prediction: {prediction}\")\n",
    "\n",
    "# Additional Feature Engineering\n",
    "df['text_length'] = df['content'].apply(len)\n",
    "df['subject_length'] = df['Subject'].apply(len)\n",
    "df['count_exclamation'] = df['content'].apply(lambda x: x.count('!'))\n",
    "df['count_links'] = df['content'].apply(lambda x: len(re.findall(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', x)))\n",
    "\n",
    "# Combine and clean text data\n",
    "df['Text'] = df['Subject'] + ' ' + df['content']\n",
    "df['Text'] = df['Text'].apply(clean_text)\n",
    "\n",
    "# Preparing the text data\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10000)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['Text'])\n",
    "\n",
    "# Converting to DataFrame to concatenate with other features\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "# Concatenate TF-IDF features with engineered features\n",
    "X = pd.concat([tfidf_df, df[['text_length', 'subject_length', 'count_exclamation', 'count_links']]], axis=1)\n",
    "y = df['Label']\n",
    "\n",
    "# RFE with RandomForestClassifier\n",
    "forest = RandomForestClassifier()\n",
    "rfe = RFE(estimator=forest, n_features_to_select=10, step=1)\n",
    "rfe.fit(X, y)\n",
    "\n",
    "# Transform X to the selected features\n",
    "X_transformed = rfe.transform(X)\n",
    "\n",
    "# Cross-validation score\n",
    "scores = cross_val_score(forest, X_transformed, y, cv=5)\n",
    "print(f\"Mean cross-validation score: {scores.mean():.2f}\")\n",
    "\n",
    "# Error analysis with confusion matrix\n",
    "y_pred = best_model.model.predict(X_test)\n",
    "conf_matrix = confusion_matrix(y_test, np.argmax(y_pred, axis=1))\n",
    "report = classification_report(y_test, np.argmax(y_pred, axis=1), target_names=label_encoder.classes_)\n",
    "print(report)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test, np.argmax(y_pred, axis=1), average='weighted')\n",
    "print(f'Recall: {recall * 100:.2f}%')\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.savefig('confusion_matrix.png')\n",
    "plt.show()\n",
    "\n",
    "# Feature Importance\n",
    "importances = forest.feature_importances_\n",
    "indices = np.argsort(importances)[-10:]  # top 10 features\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [tfidf_vectorizer.get_feature_names_out()[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.savefig('feature_importance.png')\n",
    "plt.show()\n",
    "\n",
    "# SHAP values for model explainability\n",
    "import shap\n",
    "explainer = shap.TreeExplainer(forest)\n",
    "shap_values = explainer.shap_values(X_transformed)\n",
    "\n",
    "shap.summary_plot(shap_values, X_transformed, feature_names=[tfidf_vectorizer.get_feature_names_out()[i] for i in indices])\n",
    "\n",
    "# Save the model\n",
    "best_model.model.save('best_model.h5')\n",
    "\n",
    "# Documenting the code with comments and docstrings\n",
    "# Ensure your code is well-documented with comments explaining the purpose of each section and docstrings for functions\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
